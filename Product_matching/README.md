# Задача
**Задача:** разработать алгоритм, подбирающий для определённого товара набор из пяти похожих на него. 

**Предоставленные данные:**
* **base.csv** - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.
* **train.csv** - обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) , вектор признаков и id товара из base.csv, который максимально похож на него (по мнению экспертов).
* **validation.csv** - датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из base.csv
* **validation_answer.csv** - правильные ответы к предыдущему файлу.

Файлы по ссылке: https://disk.yandex.ru/d/BBEphK0EHSJ5Jw

Задача решалась в три этапа: 
* EDA - изучение и предобработка данных;
* Разбработка алгоритма и его применение на тренировочных данных;
* Применение разработанного алгоритма на тестовых данных.
  
# EDA
В этом разделе были изучены предоставленные данные. Датасеты проверены на пропущенные значения и дубликаты. Изучено распределение данных, выбросы, взаимодействия между признаками и их важность.

Чтобы ускорить работу алгоритма и поднять оценку метрики на следуюущем этапе предложено провести работу:
* Удаление признаков с высокой мультиколлинеарностью.
* Работа с признаками, отображающими ненормальное распределение.
* Избавление от выбросов.
* Удаление менее важных признаков.
* Масштабирование признаков.
* Кластеризация признаков.
* Построение модели с быстрым поиском.

# Разработка алгоритма
На данном этапе мы попытались разработать оптимальную по скорости и качеству модель. Протестировали предложенные на этапе EDA шаги. Для обучения взяли библиотеку FAISS, а для масштабирования признаков использовали RobustScaler.  
Определили оптимальное количество кластеров с помощью метода "локтя" и библиотеки silhouette_score. 

# Тестирование модели
На данном этапе разработанный на основе FAISS алгоритм применили на тестовых данных. 
